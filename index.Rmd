---
title: "Computational Musicology "
author: "Maggie"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
---

```{r, eval = FALSE}
remotes::install_github('jaburgoyne/compmus')
```

```{r, setup}
library(tidyverse)
library(spotifyr)
library(compmus)
```

### Week 9 Self-Similarity Matrices

```{r, echo = FALSE, message = FALSE}
library(tidyverse)
library(spotifyr)
library(compmus)
uptownfunk <-
  get_tidy_audio_analysis("32OlwWuMpZ6b0aN2RZOeMS") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  uptownfunk |>
    compmus_self_similarity(pitches, "aitchison") |>
    mutate(d = d / max(d), type = "Chroma"),
  uptownfunk |>
    compmus_self_similarity(timbre, "euclidean") |>
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")
```

------------------------------------------------------------------------

This is two self-similarity matrices of uptownfunk by bruno mars (chroma and timbre)

### Week 9 - Cepstrogram

```{r}
uptownfunk <-
  get_tidy_audio_analysis("32OlwWuMpZ6b0aN2RZOeMS") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )
```

```{r}
uptownfunk |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()
```

------------------------------------------------------------------------

Once again, using the song "Uptown Funk" by Mark Ronson and Bruno Mars, I created a cepstrogram just to see what kinds of patterns or information it may show. The first level usually represents loudness, while the second level represents brightness. In the first 20 seconds, there is a slightly higher magnitude for c04. Highly likely that it is due to the high-pitched guitar in the background of the introduction. Until around 60 seconds, there was not a lot going on, that may be because the main background instrumental did not begin yet. Starting from 58 seconds, the siren in the background together with the drums are used for building up to the beat drop, which is why you can see minimal magnitude there. The beat drops (rich instrumental begins) around 67 seconds, which is also represented in row c02 as it brightens up in yellow. I also see a correlation between the trumpets used in the song and the highest magnitude/brightest yellow in the cepstogram which makes sense as it usually represents brightness. Around 170 seconds, you can see a drop in c01 and c02, this is the start of the bridge where there is nothing but vocals and drums, then eventually the bass and other instruments up to the last chorus. 


### Introduction

Welcome to Maggie's Computational Musicology Dashboard.

Firstly, I would like to introduce the corpus that I have compiled. My corpus consists of three playlists that are under the Rhythm and Blues (R&B) genre. I decided to pick R&B because it was one of my top most listened-to genres according to the end-of-the-year Spotify Wrapped. Additionally, I would like to learn more about the characteristics of the genre and its long, rich history. R&B is an interesting genre as it is common to see mixes with other popular genres like hip-hop, soul, jazz, and more. The playlists in my corpus differ in decades, the first playlist consists of the top 100 “most essential” R&B songs of the 1990s. The second and third playlists are for the decade 2000s and 2010s respectively. The 1990s playlist consists of 75 songs, the 2000s playlist consists of 100 songs and the 2010s playlist consists of 100 songs. The playlists were directly found and created by Spotify.

### Week 8 Homework

```{r}
theboyismine <-
  get_tidy_audio_analysis("6sHsXIJoEN5JpdkGMQDJxt") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)
```

```{r}
theboyismine |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(title = "The Boy Is Mine - Brandy and Monica", subtitle = "'I Love my '90s R&B' Playlist", x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```

------------------------------------------------------------------------

This chromagram is made for a specific song in the 1990s playlist called "The Boy Is Mine" by Brandy and Monica. It is a very typical, well-known, and popular song in the R&B genre. In the chromagram, it is clear that the prominent and "loudest" note is C# shown by the magnitude (also how yellow the row is). Following that, G# and F# are also very prominent. Also worth mentioning that A, B, E, and D# are also relatively high in magnitude. It all makes sense because all of these notes belong in the C# minor scale, which is also the key to this song.

I think it is super interesting to see that the first 24/25 seconds are quite empty compared to the rest of the song because only the main melody can be heard clearly and there are almost no other instruments other than some chimes. After the 25th second, the drums, background instruments, vocals, etc come in.

### Week 7 Homework Plot 1

```{r}
playlist90 <- get_playlist_audio_features("", "37i9dQZF1DX6VDO8a6cQME")
playlist00 <- get_playlist_audio_features("", "37i9dQZF1DWYmmr74INQlb")
playlist10 <- get_playlist_audio_features("", "37i9dQZF1DWXbttAJcbphz")

mixes <-
  bind_rows(
    playlist90 |> mutate(category = "1990s"),
    playlist00 |> mutate(category = "2000s"),
    playlist10 |> mutate(category = "2010s")
      )
```

```{r}
mixes_sorted <- mixes %>%
  arrange(category, track.duration_ms)

mixes_sorted <- mixes_sorted %>%
  group_by(category) %>%
  mutate(song_index = row_number())

mixes_sorted <- mixes_sorted %>%
  mutate(duration_seconds = track.duration_ms / 1000)


ggplot(mixes_sorted, aes(x = song_index, y = duration_seconds, color = category)) +
  geom_line() +
  labs(x = "Song Index", y = "Duration (seconds)", title = "Song Durations in R&B Playlists by Era") +
  theme_minimal()
```

------------------------------------------------------------------------

The first idea I wanted to explore through my corpus/playlists was looking at the change in duration of songs throughout each decade. Due to many reasons, one of them being the introduction of music streaming, songs are becoming shorter in terms of duration. Therefore, I decided to plot/visualize it based on the duration of the songs. Having recently become acquainted with R, I tried making the plots look presentable and clear. I felt that a line graph would be the most appropriate to use to visualize duration and change across time. Additionally, I decided to convert the duration from ms to seconds for clearer representation and assessment.

Looking at the first line plot and comparing the shortest duration for each decade, it is not surprising to see that the 2010s playlists include songs with the shortest duration of less than 100 seconds, which is less than one minute and a half. Moreover, the 1990s playlist included the song with the longest duration out of the entire corpus, being over 400 seconds long (almost 500 seconds, around 8 minutes).

### Week 7 Homework Plot 2

```{r}
mixes_sorted1 <- mixes %>%
  arrange(category, track.album.release_date) %>%
  mutate(duration_seconds = track.duration_ms/1000) %>%
  mutate(song_index = row_number())

ggplot(mixes_sorted1, aes(x = song_index, y = duration_seconds, color = category)) +
  geom_line() +
  labs(x = "Song Index", y = "Duration (seconds)", title = "Song Durations in R&B Playlists by Era") +
  theme_minimal()
```

------------------------------------------------------------------------

In the second line plot, a connected line graph was used to visually depict the progression of song durations across different time periods. There is a clear downward trajectory and gradual decline as time goes by, which implies that the duration of songs is getting shorter over the years




